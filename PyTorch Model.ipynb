{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch: Natural Language Processing\n",
    "#@author Chance Simmons\n",
    "#@version December 2018\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "TRAIN_DATA = \"Data/train_token.csv\"\n",
    "TEST_DATA = \"Data/test_token.csv\"\n",
    "TRAIN_LABEL = \"Data/train_label.csv\"\n",
    "TEST_LABEL = \"Data/test_label.csv\"\n",
    "VAL_DATA = \"Data/val_token.csv\"\n",
    "VAL_LABEL = \"Data/val_label.csv\"\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 1000\n",
    "HIDDEN_SIZE = 32\n",
    "VOCAB_SIZE = 10000\n",
    "LEARNING_RATE = .01\n",
    "\n",
    "\n",
    "class NLPNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Produces a RNN neural network and can be used for forward passes through the network\n",
    "    \"\"\"\n",
    "    def __init__(self,vocab_size,batch_size,hidden_size,output_size):\n",
    "        \"\"\"\n",
    "        Initialized the neural netwrk model\n",
    "\n",
    "        Parameters:\n",
    "            vocab_size: the size of the vocabulary used for embedding\n",
    "            batch_size: the number of elements that will be passed through at once\n",
    "            hidden_size: the number of hidden layer nodes to create\n",
    "            output_size: the size of the output\n",
    "        \"\"\"\n",
    "        super(NLPNet, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        #Embedding\n",
    "        self.embed = torch.nn.Embedding(vocab_size,hidden_size)\n",
    "\n",
    "        #LSTM\n",
    "        self.lstm = torch.nn.LSTM(hidden_size,hidden_size)\n",
    "\n",
    "        #Fully connected output layer\n",
    "        self.fc = torch.nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        \"\"\"\n",
    "        Intializes the hidden layers for the LSTM\n",
    "\n",
    "        Return:\n",
    "            hidden layers that will be used in the LSTM\n",
    "        \"\"\"\n",
    "        hidden_one = Variable(torch.zeros(1,self.batch_size,self.hidden_size))\n",
    "        hidden_two = Variable(torch.zeros(1,self.batch_size,self.hidden_size))\n",
    "        if torch.cuda.is_available():\n",
    "            hidden_one = hidden_one.cuda()\n",
    "            hidden_two = hidden_two.cuda()\n",
    "\n",
    "        return hidden_one, hidden_two\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the model\n",
    "\n",
    "        Parameters:\n",
    "            input_data: batched list of input lines\n",
    "\n",
    "        Return:\n",
    "            the prediction the model made\n",
    "        \"\"\"\n",
    "        #Transpose to correct shape\n",
    "        input_data = input_data.t()\n",
    "\n",
    "        #Embedding\n",
    "        input_embed  = self.embed(input_data)\n",
    "\n",
    "        #LSTM\n",
    "        out,self.hidden = self.lstm(input_embed,self.hidden)\n",
    "\n",
    "        #Output of Last LSTM Cell\n",
    "        out = self.fc(out[-1])\n",
    "\n",
    "        return torch.sigmoid(out)    \n",
    "\n",
    "\n",
    "def get_data(data_file,label_file):\n",
    "    \"\"\"\n",
    "    Gets data based off of the specified data and label file\n",
    "\n",
    "    Parameters:\n",
    "        data_file: CSV file that has data lines\n",
    "        label_file: CSV file that has label lines\n",
    "\n",
    "    Return:\n",
    "        data: list of all the data lines\n",
    "        label: list of all the label lines\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    with open(data_file,\"r\") as data, open(label_file,\"r\") as label:\n",
    "        data_reader = csv.reader(data)\n",
    "        label_reader = csv.reader(label)\n",
    "        for data_line in data_reader:\n",
    "            line_int = [int(i) for i in data_line]\n",
    "            data_list.append(line_int)\n",
    "\n",
    "        for label_line in label_reader:\n",
    "            line_int = [int(i) for i in label_line]\n",
    "            label_list.append(line_int)\n",
    "\n",
    "    return data_list,label_list\n",
    "\n",
    "def test(model,test_data,test_label):\n",
    "    \"\"\"\n",
    "    Test the model given a test dataset\n",
    "\n",
    "    Parameters:\n",
    "        model: the model that has been trained\n",
    "        test_data: the data that is used for testing\n",
    "        test_label: labels to calulate accuracy with\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    model = model.eval()\n",
    "    test_acc = []\n",
    "    start = 0\n",
    "    end = BATCH_SIZE\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(test_data) // BATCH_SIZE):\n",
    "            model.hidden = model.init_hidden()\n",
    "\n",
    "            data = test_data[start:end]\n",
    "            label = test_label[start:end]\n",
    "\n",
    "            data = torch.from_numpy(data)\n",
    "            label = torch.from_numpy(label)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                data = data.cuda()\n",
    "                label = label.cuda()\n",
    "\n",
    "            #Pass through model\n",
    "            test_out = model(data)\n",
    "\n",
    "            #Get accuracy\n",
    "            test_out = (test_out > 0.5).float()\n",
    "            test_correct = (test_out == label.float()).float().sum()\n",
    "            test_acc.append(float(100 * test_correct/test_out.shape[0]))\n",
    "\n",
    "            start += BATCH_SIZE\n",
    "            end += BATCH_SIZE\n",
    "\n",
    "    print(\"\\nTest:\\nTime Spent: {:.3f}s Accuracy: {:.2f}%\".format(\n",
    "                time.time() - start_time,np.mean(test_acc)))\n",
    "\n",
    "def validate(model,val_data,val_label,loss_function):\n",
    "    \"\"\"\n",
    "    Performs validation of the model given a validation dataset\n",
    "\n",
    "    Parameters:\n",
    "        model: the model that is being trained\n",
    "        val_data: data used for validation\n",
    "        val_label: labels used for getting accuracy\n",
    "        loss_function: used to calculate loss for the validation\n",
    "\n",
    "    Return:\n",
    "        val_acc: list of validation accuracies for each batch\n",
    "        val_loss: list of validation loss for each batch\n",
    "    \"\"\"\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_values = []\n",
    "        val_acc = []\n",
    "        val_data,val_label = shuffle(val_data,val_label)\n",
    "        start = 0\n",
    "        end = BATCH_SIZE\n",
    "        for i in range(len(val_data) // BATCH_SIZE):\n",
    "            model.hidden = model.init_hidden() \n",
    "\n",
    "            data = val_data[start:end]\n",
    "            label = val_label[start:end]\n",
    "\n",
    "            data = torch.from_numpy(data)\n",
    "            label = torch.from_numpy(label)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                data = data.cuda()\n",
    "                label = label.cuda()\n",
    "\n",
    "            #Pass through model\n",
    "            val_out = model(data)\n",
    "\n",
    "            #Get loss value\n",
    "            loss = loss_function(val_out,label.float())\n",
    "            loss_values.append(float(loss.data.mean()))\n",
    "\n",
    "            #Get accuracy\n",
    "            val_out = (val_out > 0.5).float()\n",
    "            val_correct = (val_out == label.float()).float().sum()\n",
    "            val_acc.append(float(100 * val_correct/val_out.shape[0]))\n",
    "\n",
    "            start += BATCH_SIZE\n",
    "            end += BATCH_SIZE\n",
    "    return val_acc,loss_values\n",
    "\n",
    "def train(model,loss_function,optimizer,train_data,train_label):\n",
    "    \"\"\"\n",
    "    Performs the training for one epoch\n",
    "\n",
    "    Parameters:\n",
    "        model: the model that is being trained\n",
    "        loss_function: function for calculating loss\n",
    "        optimizer: used to perform optimization on the model\n",
    "        train_data: the data that is being used to train\n",
    "        train_label: labels for correct output\n",
    "\n",
    "    Return:\n",
    "        train_acc: list of train accuracies for each batch\n",
    "        train_loss: list of train loss for each batch\n",
    "    \"\"\"\n",
    "    train_acc = []\n",
    "    train_loss = []\n",
    "    train_data,train_label = shuffle(train_data,train_label)\n",
    "    start = 0\n",
    "    end = BATCH_SIZE\n",
    "    for i in range(len(train_data) // BATCH_SIZE):\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        data = train_data[start:end]\n",
    "        label = train_label[start:end]\n",
    "\n",
    "        data = Variable(torch.from_numpy(data))\n",
    "        label = Variable(torch.from_numpy(label))\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            label = label.cuda()\n",
    "\n",
    "        #Pass through Model\n",
    "        train_out = model.forward(data)\n",
    "\n",
    "        #Get loss value\n",
    "        loss = loss_function(train_out,label.float())\n",
    "        train_loss.append(float(loss.data.mean()))\n",
    "\n",
    "        #Get accuracy\n",
    "        train_out = (train_out > 0.5).float()\n",
    "        correct_train = (train_out == label.float()).float().sum()\n",
    "        train_acc.append(float(100 * correct_train/train_out.shape[0]))\n",
    "\n",
    "        #Backpropagation    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        start += BATCH_SIZE\n",
    "        end += BATCH_SIZE\n",
    "    return train_acc,train_loss\n",
    "\n",
    "def shuffle(data,label):\n",
    "    \"\"\"\n",
    "    Shuffles the data and label in the same pattern\n",
    "\n",
    "    Parameters:\n",
    "        data: list of data lines\n",
    "        label: list of label lines\n",
    "\n",
    "    Return:\n",
    "        data: shuffled data\n",
    "        label: shuffled labels\n",
    "    \"\"\"\n",
    "    permutation = np.arange(len(data))\n",
    "    np.random.shuffle(permutation)\n",
    "    data = data[permutation]\n",
    "    label = label[permutation]\n",
    "    return data,label\n",
    "\n",
    "def plot(train_acc,train_loss,val_acc,val_loss):\n",
    "    \"\"\"\n",
    "    Plots the training and validation metrics\n",
    "\n",
    "    Parameters:\n",
    "        train_acc: accuracies from training epochs\n",
    "        train_loss: loss values for each training epoch\n",
    "        val_acc: accuracies from validation epochs\n",
    "        val_loss: loss values for each validation epoch\n",
    "    \"\"\"\n",
    "    numbered_epochs = range(1,len(train_acc)+1)\n",
    "\n",
    "    #Set Up Plot\n",
    "    figure = plt.figure()\n",
    "    plt.title(\"Accuracy Values\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xticks(range(0,len(train_acc) + 1,5))\n",
    "\n",
    "    #Plot Accuracy\n",
    "    plt.plot(numbered_epochs,train_acc,label = \"Training Accuracy\")\n",
    "    plt.plot(numbered_epochs,val_acc,label = \"Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    figure.savefig(\"Graphs/pytorch_accuracy.pdf\", bbox_inches='tight')\n",
    "\n",
    "    #Clear figure\n",
    "    plt.clf()\n",
    "\n",
    "    #Set up second plot\n",
    "    figure = plt.figure()\n",
    "    plt.title(\"Loss Values\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xticks(range(0,len(train_acc) + 1,5))\n",
    "\n",
    "    #Plot loss values\n",
    "    plt.plot(numbered_epochs,train_loss,label = \"Training Loss\")\n",
    "    plt.plot(numbered_epochs,val_loss,label = \"Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    figure.savefig(\"Graphs/pytorch_loss.pdf\", bbox_inches='tight')\n",
    "\n",
    "def plot_time(time_list):\n",
    "    numbered_epochs = range(1,len(time_list)+1)\n",
    "\n",
    "    #Set Up Plot\n",
    "    figure = plt.figure()\n",
    "    plt.title(\"PyTorch Training Time\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Time\")\n",
    "    plt.xticks(range(0,len(time_list)+1,5))\n",
    "\n",
    "    #Plot Accuracy\n",
    "    plt.plot(numbered_epochs,time_list)\n",
    "    plt.show()\n",
    "\n",
    "    figure.savefig(\"Graphs/pytorch_time.pdf\", bbox_inches='tight')\n",
    "    \n",
    "def main():\n",
    "    train_data,train_label = get_data(TRAIN_DATA,TRAIN_LABEL)\n",
    "    test_data,test_label = get_data(TEST_DATA,TEST_LABEL)\n",
    "    val_data,val_label = get_data(VAL_DATA,VAL_LABEL)\n",
    "\n",
    "    train_data,train_label = shuffle(np.array(train_data),np.array(train_label))\n",
    "    test_data,test_label = shuffle(np.array(test_data),np.array(test_label))\n",
    "    val_data,val_label = shuffle(np.array(val_data),np.array(val_label))\n",
    "\n",
    "    model = NLPNet(vocab_size = VOCAB_SIZE,batch_size = BATCH_SIZE,hidden_size = HIDDEN_SIZE,\n",
    "                    output_size = 1)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "    loss_function = torch.nn.BCELoss()\n",
    "\n",
    "    train_acc_list = []\n",
    "    train_loss_list = []\n",
    "    val_acc_list = []\n",
    "    val_loss_list = []\n",
    "    time_list = []\n",
    "\n",
    "    for epoch_count in range(1,EPOCHS + 1):\n",
    "        start_time = time.time()\n",
    "        model = model.train()\n",
    "        print(\"Epoch Count: \" + str(epoch_count) + \"/\" + str(EPOCHS))\n",
    "\n",
    "        #Train\n",
    "        train_acc,train_loss= train(model,loss_function,optimizer,train_data,train_label)\n",
    "\n",
    "        train_acc_list.append(np.mean(train_acc))\n",
    "        train_loss_list.append(np.mean(train_loss))\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        print(\"Time Spent: {:.3f}s Loss: {:.4f} Accuracy: {:.2f}%\".format(\n",
    "                time.time() - start_time,np.mean(train_loss),np.mean(train_acc)))\n",
    "\n",
    "        time_list.append(total_time)\n",
    "        \n",
    "        #Validate\n",
    "        val_acc,val_loss = validate(model,val_data,val_label,loss_function)   \n",
    "\n",
    "        val_acc_list.append(np.mean(val_acc))\n",
    "        val_loss_list.append(np.mean(val_loss))\n",
    "\n",
    "        print(\"Validation Loss: {:.4f}% Accuracy: {:.2f}\".format(float(np.mean(val_loss)),\n",
    "                                                                    float(np.mean(val_acc))))\n",
    "\n",
    "    plot(train_acc_list, train_loss_list, val_acc_list,val_loss_list)\n",
    "    plot_time(time_list)\n",
    "    \n",
    "    time_sum = 0\n",
    "    for i in range(len(time_list)):\n",
    "        time_sum += time_list[i]\n",
    "    \n",
    "    print(\"Average Time: \" + str(time_sum / len(time_list)))\n",
    "    \n",
    "    #Test\n",
    "    test(model,test_data,test_label)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
