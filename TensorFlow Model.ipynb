{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TensorFlow: Natural Language Processing\n",
    "#@author Chance Simmons\n",
    "#@version December 2018\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "TRAIN_DATA = \"Data/train_token.csv\"\n",
    "TEST_DATA = \"Data/test_token.csv\"\n",
    "TRAIN_LABEL = \"Data/train_label.csv\"\n",
    "TEST_LABEL = \"Data/test_label.csv\"\n",
    "VAL_DATA = \"Data/val_token.csv\"\n",
    "VAL_LABEL = \"Data/val_label.csv\"\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 1000\n",
    "HIDDEN_SIZE = 32\n",
    "VOCAB_SIZE = 10000\n",
    "LEARNING_RATE = .01\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "def plot(train_acc,train_loss,val_acc,val_loss):\n",
    "    \"\"\"\n",
    "    Plots the training and validation metrics\n",
    "    \n",
    "    Parameters:\n",
    "        train_acc: accuracies from training epochs\n",
    "        train_loss: loss values for each training epoch\n",
    "        val_acc: accuracies from validation epochs\n",
    "        val_loss: loss values for each validation epoch\n",
    "    \"\"\"\n",
    "    numbered_epochs = range(1,len(train_acc)+1)\n",
    "    \n",
    "    #Set Up Plot\n",
    "    figure = plt.figure()\n",
    "    plt.title(\"Accuracy Values\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xticks(range(0,len(train_acc) + 1,5))\n",
    "    \n",
    "    #Plot Accuracy\n",
    "    plt.plot(numbered_epochs,train_acc,label = \"Training Accuracy\")\n",
    "    plt.plot(numbered_epochs,val_acc,label = \"Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    figure.savefig(\"Graphs/tensorflow_accuracy.pdf\", bbox_inches='tight')\n",
    "    \n",
    "    plt.clf()\n",
    "    \n",
    "    #Set up second plot\n",
    "    figure = plt.figure()\n",
    "    plt.title(\"Loss Values\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xticks(range(0,len(train_acc) + 1,5))\n",
    "    \n",
    "    #Plot loss values\n",
    "    plt.plot(numbered_epochs,train_loss,label = \"Training Loss\")\n",
    "    plt.plot(numbered_epochs,val_loss,label = \"Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    figure.savefig(\"Graphs/tensorflow_loss.pdf\", bbox_inches='tight')\n",
    "    \n",
    "def get_data(data_file,label_file):\n",
    "    \"\"\"\n",
    "    Gets data based off of the specified data and label file\n",
    "    \n",
    "    Parameters:\n",
    "        data_file: CSV file that has data lines\n",
    "        label_file: CSV file that has label lines\n",
    "        \n",
    "    Return:\n",
    "        data: list of all the data lines\n",
    "        label: list of all the label lines\n",
    "    \"\"\"\n",
    "    with open(data_file,\"r\") as data, open(label_file,\"r\") as label:\n",
    "        data_reader = csv.reader(data)\n",
    "        label_reader = csv.reader(label)\n",
    "        data = []\n",
    "        label = []\n",
    "        for data_line in data_reader:\n",
    "            line_int = [int(i) for i in data_line]\n",
    "            data.append(line_int)\n",
    "                \n",
    "        for label_line in label_reader:\n",
    "            line_int = [int(i) for i in label_line]\n",
    "            label.append(line_int)\n",
    "    \n",
    "    data = np.array(data)\n",
    "    label = np.array(label)\n",
    "    return data,label\n",
    "\n",
    "def shuffle(data,label):\n",
    "    \"\"\"\n",
    "    Shuffles the data and label in the same pattern\n",
    "    \n",
    "    Parameters:\n",
    "        data: list of data lines\n",
    "        label: list of label lines\n",
    "    \n",
    "    Return:\n",
    "        data: shuffled data\n",
    "        label: shuffled labels\n",
    "    \"\"\"\n",
    "    permutation = np.arange(len(data))\n",
    "    np.random.shuffle(permutation)\n",
    "    data = data[permutation]\n",
    "    label = label[permutation]\n",
    "    return data,label\n",
    "\n",
    "def validate(val_data,val_label,data_input,label_output,drop,accuracy,loss,sess):\n",
    "    \"\"\"\n",
    "    Validates on the network during training\n",
    "    \n",
    "    Parameters:\n",
    "        val_data: the data lines for validating\n",
    "        val_label: the labels for validating\n",
    "        data_input: placeholder for data to be input for the model\n",
    "        label_output: placeholder for the labels to be placed for the model\n",
    "        drop: placeholder for dropout for the model\n",
    "        accuracy: caluclates the accuracy of the model\n",
    "        loss: calculates the accuracy of the model\n",
    "        sess: these tensorflow session that is being run\n",
    "    \"\"\"\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    start = 0\n",
    "    end = BATCH_SIZE\n",
    "    for j in range(len(val_data) // BATCH_SIZE):            \n",
    "        data = val_data[start:end]\n",
    "        label = val_label[start:end]\n",
    "            \n",
    "        feed_dict = {data_input: data,\n",
    "                     label_output: label,\n",
    "                     drop: 1}\n",
    "            \n",
    "        loss_value, accuracy_value = sess.run([loss,accuracy], feed_dict = feed_dict)\n",
    "            \n",
    "        val_loss.append(loss_value)\n",
    "        val_acc.append(accuracy_value * 100)\n",
    "        \n",
    "        start += BATCH_SIZE\n",
    "        end += BATCH_SIZE\n",
    "            \n",
    "    print(\"Validation Loss: {:.4f} Accuracy: {:.2f}%\".format(np.mean(val_loss), \n",
    "                                                                 np.mean(val_acc)))\n",
    "    return val_acc,val_loss\n",
    "        \n",
    "def test(test_data,test_label,data_input,label_output,drop,accuracy,sess):\n",
    "    \"\"\"\n",
    "    Performs test of the the trained model\n",
    "    \n",
    "    Parameters:\n",
    "        test_data: the data lines for testing\n",
    "        test_label: the labels for testing\n",
    "        data_input: placeholder for data to be input for the model\n",
    "        label_output: placeholder for the labels to be placed for the model\n",
    "        drop: placeholder for dropout for the model\n",
    "        accuracy: caluclates the accuracy of the model\n",
    "        sess: these tensorflow session that is being run\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    test_acc = []\n",
    "    start = 0\n",
    "    end = BATCH_SIZE\n",
    "    for i in range(len(test_data) // BATCH_SIZE):      \n",
    "        data = test_data[start:end]\n",
    "        label = test_label[start:end]\n",
    "            \n",
    "        feed_dict = {data_input: data,\n",
    "                     label_output:label,\n",
    "                     drop: 1}\n",
    "          \n",
    "        accuracy_value = sess.run([accuracy], feed_dict=feed_dict)\n",
    "        test_acc.append(accuracy_value * 100)\n",
    "        \n",
    "        start += BATCH_SIZE\n",
    "        end += BATCH_SIZE\n",
    "        \n",
    "    print(\"\\nTest:\\nTime Spent: {:.3f}s Accuracy: {:.2f}%\".format(\n",
    "              time.time() - start_time,float(np.mean(test_acc) * 100)))\n",
    "\n",
    "def train(train_data,train_label,data_input,label_output,drop,accuracy,loss,optimizer,sess):\n",
    "    \"\"\"\n",
    "    Performs training if the model for a single epoch\n",
    "    \n",
    "    Parameters:\n",
    "        train_data: the data lines for testing\n",
    "        train_label: the labels for testing\n",
    "        data_input: placeholder for data to be input for the model\n",
    "        label_output: placeholder for the labels to be placed for the model\n",
    "        drop: placeholder for dropout for the model\n",
    "        accuracy: caluclates the accuracy of the model\n",
    "        loss: calculates loss for the training step\n",
    "        optimizer: used to perform optimization of the model\n",
    "        sess: these tensorflow session that is being run\n",
    "    \"\"\"\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    start = 0\n",
    "    end = BATCH_SIZE\n",
    "    for i in range(len(train_data) // BATCH_SIZE):            \n",
    "            data = train_data[start:end]\n",
    "            label = train_label[start:end]\n",
    "            \n",
    "            feed_dict = {data_input: data,\n",
    "                         label_output:label,\n",
    "                         drop: .5}\n",
    "          \n",
    "            optim, loss_value,accuracy_value = sess.run([optimizer, loss, accuracy],\n",
    "                                                        feed_dict=feed_dict)\n",
    "            \n",
    "            train_loss.append(loss_value)\n",
    "            train_acc.append(accuracy_value * 100)\n",
    "            \n",
    "            start += BATCH_SIZE\n",
    "            end += BATCH_SIZE\n",
    "    return train_acc,train_loss\n",
    "def model():\n",
    "    \"\"\"\n",
    "    Creates the RNN and returns the different parts of the model\n",
    "    \n",
    "    Return:\n",
    "        data_input: used as a data placeholder\n",
    "        label_output: used as a label placeholder\n",
    "        drop: used as a dropout placeholder\n",
    "        optimizer: used to perform optimization\n",
    "        loss: used to calculate loss\n",
    "        accuracy: used to calculate accuracy\n",
    "    \"\"\"\n",
    "    #Create Placeholders\n",
    "    data_input = tf.placeholder(tf.int32, [None,None])\n",
    "    label_output = tf.placeholder(tf.float32,[None,1])\n",
    "    drop = tf.placeholder(tf.float32)\n",
    "    \n",
    "    #Embedding\n",
    "    embedding = tf.Variable(tf.random_uniform([VOCAB_SIZE,HIDDEN_SIZE],-1,1))\n",
    "    embed = tf.nn.embedding_lookup(embedding,data_input)\n",
    "    \n",
    "    #LSTM\n",
    "    lstm = tf.nn.rnn_cell.LSTMCell(HIDDEN_SIZE)\n",
    "    init_state = lstm.zero_state(BATCH_SIZE,dtype=tf.float32)\n",
    "    \n",
    "    lstm_drop = tf.contrib.rnn.DropoutWrapper(lstm,output_keep_prob = drop)\n",
    "    lstm_out,state = tf.nn.dynamic_rnn(lstm,embed,initial_state = init_state,dtype=tf.float32)\n",
    "    \n",
    "    #Output\n",
    "    weight = tf.Variable(tf.random_normal([HIDDEN_SIZE,1]))\n",
    "    bias = tf.Variable(tf.random_normal([1]))\n",
    "    \n",
    "    lstm_out = tf.transpose(lstm_out,[1,0,2])\n",
    "    prediction = tf.matmul(tf.cast(lstm_out[-1],tf.float32),weight) + bias\n",
    "    \n",
    "    #Accuracy\n",
    "    correct = tf.equal(tf.round(tf.nn.sigmoid(prediction)), label_output)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "    \n",
    "    #Loss and Optimizer\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = prediction,labels \n",
    "                                                                  = label_output))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = LEARNING_RATE).minimize(loss)\n",
    "    \n",
    "    return data_input,label_output,drop,optimizer,loss,accuracy\n",
    "\n",
    "def plot_time(time_list):\n",
    "    numbered_epochs = range(1,len(time_list)+1)\n",
    "    \n",
    "    #Set Up Plot\n",
    "    figure = plt.figure()\n",
    "    plt.title(\"TensorFlow Training Time\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Time\")\n",
    "    plt.xticks(range(0,len(time_list)+1,5))\n",
    "    \n",
    "    #Plot Accuracy\n",
    "    plt.plot(numbered_epochs,time_list)\n",
    "    plt.show()\n",
    "    \n",
    "    figure.savefig(\"Graphs/tensorflow_time.pdf\", bbox_inches='tight')\n",
    "    \n",
    "def main():\n",
    "    train_data,train_label = get_data(TRAIN_DATA,TRAIN_LABEL)\n",
    "    val_data,val_label = get_data(VAL_DATA,VAL_LABEL)\n",
    "    test_data,test_label = get_data(TEST_DATA,TEST_LABEL)\n",
    "    \n",
    "    data_input,label_output,drop,optimizer, loss, accuracy = model()\n",
    "    \n",
    "    train_acc_list = []\n",
    "    train_loss_list = []\n",
    "    val_acc_list = []\n",
    "    val_loss_list = []\n",
    "    time_list = []\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(1,EPOCHS + 1):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_data,train_label = shuffle(train_data,train_label)\n",
    "        print(\"Epoch Count: \" + str(epoch) + \"/\" + str(EPOCHS))\n",
    "        \n",
    "        #Training\n",
    "        train_acc,train_loss = train(train_data,train_label,data_input,label_output,\n",
    "                                     drop,accuracy,loss,optimizer,sess)\n",
    "        \n",
    "        train_acc_list.append(np.mean(train_acc))\n",
    "        train_loss_list.append(np.mean(train_loss))\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(\"Time Spent: {:.3f}s Loss: {:.4f} Accuracy: {:.2f}%\".format(\n",
    "              total_time,np.mean(train_loss),np.mean(train_acc)))\n",
    "        \n",
    "        time_list.append(total_time)\n",
    "        \n",
    "        #Validate\n",
    "        val_acc,val_loss = validate(val_data,val_label,data_input,label_output,drop,accuracy,\n",
    "                                    loss,sess)\n",
    "        val_acc_list.append(np.mean(val_acc))\n",
    "        val_loss_list.append(np.mean(val_loss))\n",
    "            \n",
    "    plot(train_acc_list,train_loss_list,val_acc_list,val_loss_list)\n",
    "    plot_time(time_list)\n",
    "    \n",
    "    time_sum = 0\n",
    "    for i in range(len(time_list)):\n",
    "        time_sum += time_list[i]\n",
    "        \n",
    "    print(\"Average Time: \" + str(time_sum / len(time_list)))\n",
    "    \n",
    "    #Test  \n",
    "    test(test_data,test_label,data_input,label_output,drop,accuracy,sess)\n",
    "    sess.close()\n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
